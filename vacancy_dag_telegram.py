# ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¹

import pandas as pd
import numpy as np
import requests
import time


# Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³ hh

def get_strict_moscow_vacancies():
    """Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµÑ‚ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾ÑĞºĞ¾Ğ²ÑĞºĞ¸Ğµ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¸"""

    url = "https://api.hh.ru/vacancies"
    all_vacancies = []

    # Ğ‘Ğ¾Ğ»ĞµĞµ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹
    params = {
        'professional_role': [10, 12, 13, 15, 24, 25, 34],  # data-Ñ€Ğ¾Ğ»Ğ¸
        'text': 'sql OR spark OR python OR airflow OR hadoop OR R OR oracle '
                'OR kafka OR pyspark OR pandas OR vertica OR postgresql OR sqlite OR git'
                'OR Ğ´Ğ°Ñ‚Ğ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ğº OR ÑÑ‚Ğ°Ğ¶ĞµÑ€ OR Ğ´Ğ°Ñ‚Ğ° Ğ¸Ğ½Ğ¶ĞµĞ½ĞµÑ€',
        #'text': 'python OR sql OR spark OR airflow OR etl OR dwh',
        'area': 1,  # ĞœĞ¾ÑĞºĞ²Ğ°
        'per_page': 100,
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹
        #'search_field': 'name',  # Ğ¸ÑĞºĞ°Ñ‚ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ² Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸ÑÑ…
        # 'only_with_salary': True,  # Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ Ğ·Ğ°Ñ€Ğ¿Ğ»Ğ°Ñ‚Ğ¾Ğ¹ (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)
    }

    print("ğŸ” Ğ¡Ğ±Ğ¾Ñ€ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾ÑĞºĞ¾Ğ²ÑĞºĞ¸Ñ… Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹...")
    response = requests.get(url, params=params)

    if response.status_code != 200:
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {response.status_code}")
        return pd.DataFrame()

    data = response.json()
    total_found = data['found']
    total_pages = data['pages']

    print(f"ğŸ¯ ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹ (ĞœĞ¾ÑĞºĞ²Ğ°): {total_found}")
    print(f"ğŸ“„ Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ†: {total_pages}")

    # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ²ÑĞµ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹
    for page in range(total_pages):
        params['page'] = page
        response = requests.get(url, params=params)

        if response.status_code == 200:
            page_data = response.json()

            # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒĞµĞ¼ ÑÑ€Ğ°Ğ·Ñƒ Ğ¿Ñ€Ğ¸ ÑĞ±Ğ¾Ñ€Ğµ
            moscow_vacancies = [v for v in page_data['items'] if v['area']['name'] == 'ĞœĞ¾ÑĞºĞ²Ğ°']
            all_vacancies.extend(moscow_vacancies)

            print(f"âœ… Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ° {page + 1}/{total_pages}: {len(moscow_vacancies)} Ğ¼Ğ¾ÑĞºĞ¾Ğ²ÑĞºĞ¸Ñ… Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹")

            time.sleep(0.1)

    print(f"ğŸ‰ Ğ¡Ğ¾Ğ±Ñ€Ğ°Ğ½Ğ¾ Ğ¼Ğ¾ÑĞºĞ¾Ğ²ÑĞºĞ¸Ñ… Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹: {len(all_vacancies)}")

    #return pd.DataFrame(all_vacancies)
    return {'items': all_vacancies, 'found': len(all_vacancies)}

# Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾ÑĞºĞ¾Ğ²ÑĞºĞ¸Ğµ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¸
#vacancy_keys = get_strict_moscow_vacancies()


# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ñ‚Ğ° Ñ„Ñ€ÑĞ¹Ğ¼Ğ°

def parse_hh_vacancies_with_status(data):
    vacancies_list = []

    for vacancy in data['items']:
        # Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ²Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
        employer = vacancy.get('employer') or {}
        area = vacancy.get('area') or {}
        experience = vacancy.get('experience') or {}
        employment = vacancy.get('employment') or {}
        salary = vacancy.get('salary') or {}
        metro_stations = vacancy.get('metro_stations', [{}])[0] if vacancy.get('metro_stations') else {}
        
        parsed = {
            'id': vacancy.get('id', ''),
            'name': vacancy.get('name', ''),
            'employer_name': employer.get('name', ''),
            'url': vacancy.get('alternate_url', ''),
            'published_at': vacancy.get('published_at', ''),
            'status': vacancy.get('type', {}).get('name', 'ĞĞµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾'),
            
            
            # ğŸ”¥ Ğ˜ĞĞ¤ĞĞ ĞœĞĞ¦Ğ˜Ğ¯ Ğ Ğ¡Ğ¢ĞĞ¢Ğ£Ğ¡Ğ•
            'archived': vacancy.get('archived', False),
            'response_url': vacancy.get('response_url', ''),
            'has_test': vacancy.get('has_test', False),
            'response_letter_required': vacancy.get('response_letter_required', False),

            # ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ
            'snippet_requirement': vacancy.get('snippet', {}).get('requirement', ''),
            'snippet_responsibility': vacancy.get('snippet', {}).get('responsibility', ''),

            # Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ¾Ğ´Ğ°Ñ‚ĞµĞ»ÑŒ
            #'employer_name': employer.get('name', ''),
            'employer_trusted': employer.get('trusted', False),

            # Ğ›Ğ¾ĞºĞ°Ñ†Ğ¸Ñ
            'area_name': area.get('name', ''),

            # ĞĞ¿Ñ‹Ñ‚ Ğ¸ Ğ·Ğ°Ğ½ÑÑ‚Ğ¾ÑÑ‚ÑŒ
            'experience_name': experience.get('name', ''),
            'employment_name': employment.get('name', ''),

            # Ğ—Ğ°Ñ€Ğ¿Ğ»Ğ°Ñ‚Ğ°
            'salary_from': salary.get('from'),
            'salary_to': salary.get('to'),
            'salary_currency': salary.get('currency', ''),
            'salary_gross': salary.get('gross'),

            # ĞœĞµÑ‚Ñ€Ğ¾
            'metro_station_name': metro_stations.get('station_name', ''),
            'metro_line_name': metro_stations.get('line_name', '')
        }

        vacancies_list.append(parsed)

    vacancy_data = pd.DataFrame(vacancies_list)
    
    from datetime import date, datetime

    # Ğ¡ĞµĞ³Ğ¾Ğ´Ğ½ÑÑˆĞ½ÑÑ Ğ´Ğ°Ñ‚Ğ°
    today = date.today()

    vacancy_data['report_date'] = today

    cols = vacancy_data.columns.tolist()
    cols = [cols[-1]] + cols[:-1]

    vacancy_data = vacancy_data[cols]

    return vacancy_data

# Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼
#vacancy_data = parse_hh_vacancies_with_status(vacancy_keys)





# ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹
def link_data_base(data):
    import sqlite3
    
    link = '/mnt/d/Data engineer/SQLite/vacancy_new.db'
    conn = sqlite3.connect(link)

    # Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—Ğ£Ğ•Ğœ ĞĞĞ’ĞĞ• Ğ˜ĞœĞ¯ Ğ¢ĞĞ‘Ğ›Ğ˜Ğ¦Ğ«
    table_name = 'hh_vacancies_new'  

    try:
        # Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
        vacancy_data_total = pd.read_sql(f"SELECT * FROM {table_name}", conn)
        
        # Ğ•ÑĞ»Ğ¸ Ğ² Ğ‘Ğ” Ğ½ĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ñ… ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ğ¾Ğ², Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¸Ñ… Ñ NaN Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸ÑĞ¼Ğ¸
        for col in data.columns:
            if col not in vacancy_data_total.columns:
                vacancy_data_total[col] = None
                
    except Exception as e:
        print(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ñ‡Ñ‚ĞµĞ½Ğ¸Ğ¸ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹: {e}")
        # Ğ•ÑĞ»Ğ¸ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹ Ğ½ĞµÑ‚, ÑĞ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ DataFrame Ñ Ğ½ÑƒĞ¶Ğ½Ğ¾Ğ¹ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¾Ğ¹
        vacancy_data_total = pd.DataFrame(columns=data.columns)
    
    # Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ²
    vacancy_data_total = vacancy_data_total.drop_duplicates(subset=['id'], keep='last')

    vacancy_current = set(data['id'])
    vacancy_old = set(vacancy_data_total['id'])

    # Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ½ĞµÑ‚ Ğ² Ğ‘Ğ”
    vacancy_new = vacancy_current.difference(vacancy_old)

    # Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ñ Ğ½Ğ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸ÑĞ¼Ğ¸
    vacancy_data_new = data[data['id'].isin(vacancy_new)].copy(deep=True)
    
    conn.close()
    return vacancy_data_new

#vacancy_data_new = link_data_base(vacancy_data)


############################################################################

# ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ² Ñ‚ĞµĞ»ĞµĞ³Ñ€Ğ°Ğ¼Ğ¼
def telegram_bot(df):
    import requests
    
    BOT_TOKEN = "ÑƒĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ñ‚Ğ¾ĞºĞµĞ½"
    CHAT_ID = "id"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ĞµÑÑ‚ÑŒ Ğ»Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¸
    if df.empty:
        print("ĞĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸")
        
        # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ñ‡Ñ‚Ğ¾ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹ Ğ½ĞµÑ‚
        message = "ğŸ“­ ĞĞ° ÑĞµĞ³Ğ¾Ğ´Ğ½Ñ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾"
    else:
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ñ Ñ Ğ½Ğ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸ÑĞ¼Ğ¸
        key_vacancy = df.apply(
            lambda row: {
                'title': f"{row['name']}, ({row['employer_name']})",
                'url': row['url']
            }, 
            axis=1
        ).tolist()

        # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ñ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸ÑĞ¼Ğ¸
        message = "ğŸ’¼ğŸ”¥ğŸ’² ĞĞ¾Ğ²Ñ‹Ğµ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¸:\n\n"
        for vacancy in key_vacancy:
            message += f"â€¢ {vacancy['title']}\n{vacancy['url']}\n\n"
        
        if len(message) > 4000:
            message = message[:4000] + "..."
    
    # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ² Ğ»ÑĞ±Ğ¾Ğ¼ ÑĞ»ÑƒÑ‡Ğ°Ğµ
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    data = {
        'chat_id': CHAT_ID,
        'text': message
    }
    
    try:
        response = requests.post(url, data=data)
        if response.status_code == 200:
            result_msg = f"âœ… Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾: {len(df) if not df.empty else 0} Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹"
            print(result_msg)
            return result_msg
        else:
            error_msg = f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° {response.status_code}: {response.text}"
            print(error_msg)
            return error_msg
    except Exception as e:
        error_msg = f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ: {e}"
        print(error_msg)
        return error_msg

############################################################################




# Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹ Ğ² Ğ½Ğ¾Ğ²ÑƒÑ


import sqlite3
import pandas as pd


def chek_data_base_load(data, db_link, table_name='hh_vacancies_new'):

    conn = sqlite3.connect(db_link)

    try:
        # 1. Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ ID Ğ¸Ğ· Ğ‘Ğ”
        existing_ids = pd.read_sql(f"SELECT id FROM {table_name}", conn)['id'].tolist()
        
        # 2. Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ - Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚Ğµ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ½ĞµÑ‚ Ğ² Ğ‘Ğ”
        data = data[~data['id'].isin(existing_ids)]
        
        print(f"ğŸ“Š Ğ’ÑĞµĞ³Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹: {len(data)}")
        print(f"âœ… Ğ£Ğ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹: {len(data)}")
        print(f"ğŸš« Ğ”ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ²: {len(data) - len(data)}")
        
        # 3. Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸
        if not data.empty:
            data.to_sql(table_name, conn, if_exists='append', index=False)
            print(f"ğŸ’¾ Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ {len(data)} Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹ Ğ² Ğ‘Ğ”")
        else:
            print("â„¹ï¸ ĞĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ")
            
    except Exception as e:
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
    finally:
        conn.close()

#db_link = 'D:/Data engineer/SQLite/vacancy.db'

#chek_data_base_load(data = vacancy_data_new, db_link = db_link, table_name='hh_vacancies')


from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta

# Ğ’Ğ°ÑˆĞ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ñ‹ Ğ²Ñ‹ÑˆĞµ Ğ² ÑÑ‚Ğ¾Ğ¼ Ğ¶Ğµ Ñ„Ğ°Ğ¹Ğ»Ğµ
# (Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ÑÑ, Ñ‡Ñ‚Ğ¾ get_strict_moscow_vacancies, parse_hh_vacancies_with_status, 
# link_data_base, chek_data_base_load ÑƒĞ¶Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ñ‹ Ğ²Ñ‹ÑˆĞµ)

# ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ DAG

from airflow.providers.standard.operators.python import PythonOperator  # ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚

# ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ DAG
with DAG(
    'vacancy_dag_telegram',
    start_date=datetime(2024, 11, 18),
    schedule='0 19 * * *',
    catchup=False,
    default_args={
        'owner': 'airflow',
        'retries': 1,
        'retry_delay': timedelta(minutes=5),
    },
    description='Ğ•Ğ¶ĞµĞ´Ğ½ĞµĞ²Ğ½Ğ¾Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸ÑÑ…'
) as dag:
    
    # Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° 1: ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
    task_parcing_data = PythonOperator(
        task_id='task_parcing_data',
        python_callable=get_strict_moscow_vacancies
    )

    # Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° 2: Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ DataFrame
    def parse_hh_vacancies_with_status_wrapper(**kwargs):
        ti = kwargs['ti']
        vacancy_keys = ti.xcom_pull(task_ids='task_parcing_data')

        # Ğ’Ñ‹Ğ·Ğ¾Ğ² Ğ²Ğ°ÑˆĞµĞ¹ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸
        return parse_hh_vacancies_with_status(vacancy_keys)

    task_create_Data_Frame = PythonOperator(
        task_id='task_create_Data_Frame',
        python_callable = parse_hh_vacancies_with_status_wrapper
    )

    # Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° 3: ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹
    def link_data_base_wrapper(**kwargs):

        ti = kwargs['ti']
        vacancy_data = ti.xcom_pull(task_ids='task_create_Data_Frame')
        return link_data_base(vacancy_data)

    task_new_vacancies = PythonOperator(
        task_id='task_new_vacancies',
        python_callable = link_data_base_wrapper
    )


    # Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° 4: ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ² Ğ¢ĞµĞ»ĞµĞ³Ñ€Ğ°Ğ¼Ğ¼
    def send_telegram_message(**kwargs):
        ti = kwargs['ti']
        
        # Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ĞµĞ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸
        df =ti.xcom_pull(task_ids = 'task_new_vacancies')

        # Ğ’Ñ‹Ğ·Ğ¾Ğ² Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸
        return telegram_bot(df)
    
    task_send_telegram = PythonOperator(
        task_id = 'task_send_telegram',
        python_callable = send_telegram_message
    )


    # Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° 5: Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ² Ğ±Ğ°Ğ·Ñƒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
    def chek_data_base_load_wrapper(**kwargs):
        ti = kwargs['ti']
        data = ti.xcom_pull(task_ids='task_new_vacancies')
        return chek_data_base_load(data, '/mnt/d/Data engineer/SQLite/vacancy_new.db', 'hh_vacancies_new') # Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ñ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ¼ Ğ´Ğ»Ñ SQLite

    task_load_data_to_database = PythonOperator(
        task_id='task_load_data_to_database',
        python_callable=chek_data_base_load_wrapper
    )

    # ĞŸĞ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ
    task_parcing_data >> task_create_Data_Frame >> task_new_vacancies >> task_send_telegram  >> task_load_data_to_database

